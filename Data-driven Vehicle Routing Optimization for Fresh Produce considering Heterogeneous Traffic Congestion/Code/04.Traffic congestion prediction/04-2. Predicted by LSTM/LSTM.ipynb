{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用3月-11月的数据进行训练，预测11月24的拥堵状况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、导入工具包 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据处理库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#读取Excel及数据保存为Excel\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 21:39:06.617412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 21:39:06.790759: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-19 21:39:07.653609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: (null error message); LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:07.653656: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-19 21:39:09.669346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:09.678682: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:09.678718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#导入绘图工具包\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#离线绘图\n",
    "pyplt = py.offline.plot\n",
    "#随机生成数据\n",
    "import random\n",
    "#使得输出的数据可以完整打印出来全部的行列\n",
    "#显示所有列\n",
    "#pd.set_option('display.max_columns',None)\n",
    "#显示所有行\n",
    "#pd.set_option('display.max_rows',None)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  \n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3' # 只显示 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 21:39:12.341536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:12.355073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:12.368210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:12.546238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:12.559542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:12.572489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-19 21:39:12.572541: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# 设置gpu内存自增长\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取某条路径的全部数据\n",
    "corrected_roadData = pd.read_csv(r'./data/road%d.csv'%number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>EXPONENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/7/1 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/7/1 0:05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/7/1 0:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/7/1 0:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/7/1 0:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42043</th>\n",
       "      <td>2018/11/23 23:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42044</th>\n",
       "      <td>2018/11/23 23:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42045</th>\n",
       "      <td>2018/11/23 23:45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42046</th>\n",
       "      <td>2018/11/23 23:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42047</th>\n",
       "      <td>2018/11/23 23:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42048 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  Monday  Tuesday  Wednesday  Thursday  Friday  \\\n",
       "0         2018/7/1 0:00       0        0          0         0       0   \n",
       "1         2018/7/1 0:05       0        0          0         0       0   \n",
       "2         2018/7/1 0:10       0        0          0         0       0   \n",
       "3         2018/7/1 0:15       0        0          0         0       0   \n",
       "4         2018/7/1 0:20       0        0          0         0       0   \n",
       "...                 ...     ...      ...        ...       ...     ...   \n",
       "42043  2018/11/23 23:35       0        0          0         0       0   \n",
       "42044  2018/11/23 23:40       0        0          0         0       0   \n",
       "42045  2018/11/23 23:45       0        0          0         0       0   \n",
       "42046  2018/11/23 23:50       0        0          0         0       0   \n",
       "42047  2018/11/23 23:55       0        0          0         0       0   \n",
       "\n",
       "       Saturday  Sunday  EXPONENT  \n",
       "0             0       1         3  \n",
       "1             0       1         3  \n",
       "2             0       1         2  \n",
       "3             0       1         3  \n",
       "4             0       1         3  \n",
       "...         ...     ...       ...  \n",
       "42043         1       0         2  \n",
       "42044         1       0         2  \n",
       "42045         1       0         2  \n",
       "42046         1       0         2  \n",
       "42047         1       0         2  \n",
       "\n",
       "[42048 rows x 9 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_roadData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入数据的长度，用前3天的数据预测24小时以后的一个时刻的数据，每天有288个观测值\n",
    "sequence_len = 3 * 288   #训练数据：从当前时间点来看前面5天的数据\n",
    "delay = 288  #预测数据：从当前时间点来看后一天的数据\n",
    "for_predict = (5 * 288 - 1)  #用于预测的数据，不参与模型训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 3],\n",
       "       [0, 0, 0, ..., 0, 1, 3],\n",
       "       [0, 0, 0, ..., 0, 1, 2],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 2],\n",
       "       [0, 0, 0, ..., 1, 0, 2],\n",
       "       [0, 0, 0, ..., 1, 0, 2]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#因为是一个单输入和单输出，所以只需要提取出roadData中的第三列数据，然后重新赋值给roadData即可\n",
    "#此时输出的结果是一个二维array数组\n",
    "roadData_array = corrected_roadData.iloc[:,1:].values\n",
    "roadData_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个空列表data_，每六天的数据为一组（共1152条），将全部数据（共76032条）去除用于预测的数据（2015条）进行划分（全部数据量/六天的数据总量）组，每条数据只有一个变量\n",
    "data_ = []\n",
    "for i in range(len(roadData_array)-sequence_len-delay-for_predict):\n",
    "    data_.append(roadData_array[i:i+sequence_len+delay])\n",
    "#把data_转化为array数组，三维（全部数据量，每组数据量，每条数据所含变量）\n",
    "data_ = np.array(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把全部组的数据的顺序打乱\n",
    "np.random.shuffle(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#高维数组切片，切出x（特征）和y（标签）\n",
    "x = data_[: , :3*288, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_[: ,-1, 7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39457, 864, 8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39457, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练数据和测试数据，其中，80%为训练数据，20%为测试数据\n",
    "split_b = int(data_.shape[0]*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x[ : split_b]\n",
    "train_y = y[ : split_b]\n",
    "test_x = x[split_b : ]\n",
    "test_y = y[split_b : ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31565, 864, 8), (31565, 1))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape , train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7892, 864, 8), (7892, 1))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape , test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#神经网络喜欢分布在一定范围内的数据，所以要进行数据标准化。\n",
    "#在进行数据标准化过程中需要注意，我们不可能生活在未来，因此标准化减均值除方差的均值和方差应该是训练集上的，不应该包含测试集数据\n",
    "mean = train_x.mean(axis = 0)  #求列上的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14687153, 0.14585775, 0.13819103, ..., 0.13809599, 0.14677649,\n",
       "        3.03377158],\n",
       "       [0.14680817, 0.14582607, 0.13822272, ..., 0.13822272, 0.14674481,\n",
       "        3.03586251],\n",
       "       [0.14683985, 0.14579439, 0.1382544 , ..., 0.13815935, 0.14671313,\n",
       "        3.03557738],\n",
       "       ...,\n",
       "       [0.13781087, 0.1382544 , 0.13933154, ..., 0.14522414, 0.14630128,\n",
       "        3.02977982],\n",
       "       [0.13781087, 0.13819103, 0.13933154, ..., 0.1451291 , 0.14645969,\n",
       "        3.02886108],\n",
       "       [0.13777919, 0.13822272, 0.13929986, ..., 0.14531918, 0.14639633,\n",
       "        3.02765722]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = train_x.std(axis = 0,dtype=float)  #求列上的方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35397781, 0.35296355, 0.34510038, ..., 0.34500071, 0.35388297,\n",
       "        1.3905385 ],\n",
       "       [0.35391459, 0.35293176, 0.34513359, ..., 0.34513359, 0.35385134,\n",
       "        1.38711003],\n",
       "       [0.3539462 , 0.35289997, 0.3451668 , ..., 0.34506716, 0.35381971,\n",
       "        1.38874942],\n",
       "       ...,\n",
       "       [0.34470137, 0.3451668 , 0.34629216, ..., 0.35232668, 0.353408  ,\n",
       "        1.38661437],\n",
       "       [0.34470137, 0.34510038, 0.34629216, ..., 0.35223095, 0.35356647,\n",
       "        1.38824359],\n",
       "       [0.34466807, 0.34513359, 0.34625916, ..., 0.35242236, 0.3535031 ,\n",
       "        1.38872442]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (train_x -mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = (test_x - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31565, 864, 8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31565, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# （五）建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM网络dense层接受的数据就是三维的\n",
    "model1.add(layers.LSTM(96,input_shape = (train_x.shape[1:]))) #32是隐藏单元数，默认激活函数是tanh\n",
    "model1.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用一个回调函数，在学习中降低学习速率，让前期快速下降，后期缓慢下降，避免错过最优值\n",
    "#监控'val_loss'，如果连续3个'val_loss'不变，就降低学习速率，降低为原来的factor倍，降低到min_lr就停止降低\n",
    "lr_reduce=keras.callbacks.ReduceLROnPlateau('val_loss',patience = 3, factor=0.5, min_lr=0.000001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建EarlyStopping回调函数,monitor参数表示需要监视的指标，一般选择验证集上的损失函数；\n",
    "#patience参数表示当指标不再提升时，模型需要多少个Epoch才停止训练。\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "# 创建TensorBoard回调函数\n",
    "tensorboard_callback = TensorBoard(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mae',\n",
    "             metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 96)                40320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,417\n",
      "Trainable params: 40,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f56a817f9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f56a817f9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f56a817f9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.7855 - mae: 0.7855WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f56a8217cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f56a8217cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f56a8217cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "247/247 [==============================] - 206s 827ms/step - loss: 0.7855 - mae: 0.7855 - val_loss: 0.7137 - val_mae: 0.7137 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "247/247 [==============================] - 205s 832ms/step - loss: 0.7020 - mae: 0.7020 - val_loss: 0.7130 - val_mae: 0.7130 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "247/247 [==============================] - 201s 814ms/step - loss: 0.6873 - mae: 0.6873 - val_loss: 0.7040 - val_mae: 0.7040 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "247/247 [==============================] - 202s 820ms/step - loss: 0.6768 - mae: 0.6768 - val_loss: 0.6882 - val_mae: 0.6882 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "247/247 [==============================] - 205s 828ms/step - loss: 0.6684 - mae: 0.6684 - val_loss: 0.6705 - val_mae: 0.6705 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "247/247 [==============================] - 204s 826ms/step - loss: 0.6577 - mae: 0.6577 - val_loss: 0.6897 - val_mae: 0.6897 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "247/247 [==============================] - 208s 841ms/step - loss: 0.6503 - mae: 0.6503 - val_loss: 0.6635 - val_mae: 0.6635 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "247/247 [==============================] - 204s 826ms/step - loss: 0.6413 - mae: 0.6413 - val_loss: 0.6540 - val_mae: 0.6540 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "247/247 [==============================] - 199s 807ms/step - loss: 0.6428 - mae: 0.6428 - val_loss: 0.6563 - val_mae: 0.6563 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "247/247 [==============================] - 203s 824ms/step - loss: 0.6332 - mae: 0.6332 - val_loss: 0.6437 - val_mae: 0.6437 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "247/247 [==============================] - 198s 801ms/step - loss: 0.6280 - mae: 0.6280 - val_loss: 0.6434 - val_mae: 0.6434 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "247/247 [==============================] - 202s 819ms/step - loss: 0.6264 - mae: 0.6264 - val_loss: 0.6454 - val_mae: 0.6454 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "247/247 [==============================] - 198s 801ms/step - loss: 0.6219 - mae: 0.6219 - val_loss: 0.6436 - val_mae: 0.6436 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "247/247 [==============================] - 203s 823ms/step - loss: 0.6227 - mae: 0.6227 - val_loss: 0.6476 - val_mae: 0.6476 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "247/247 [==============================] - 197s 798ms/step - loss: 0.6068 - mae: 0.6068 - val_loss: 0.6288 - val_mae: 0.6288 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "247/247 [==============================] - 198s 804ms/step - loss: 0.6035 - mae: 0.6035 - val_loss: 0.6252 - val_mae: 0.6252 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "247/247 [==============================] - 202s 818ms/step - loss: 0.6004 - mae: 0.6004 - val_loss: 0.6198 - val_mae: 0.6198 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "247/247 [==============================] - 204s 828ms/step - loss: 0.5978 - mae: 0.5978 - val_loss: 0.6238 - val_mae: 0.6238 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "247/247 [==============================] - 202s 820ms/step - loss: 0.5991 - mae: 0.5991 - val_loss: 0.6212 - val_mae: 0.6212 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "247/247 [==============================] - 201s 812ms/step - loss: 0.5949 - mae: 0.5949 - val_loss: 0.6180 - val_mae: 0.6180 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "247/247 [==============================] - 202s 820ms/step - loss: 0.5915 - mae: 0.5915 - val_loss: 0.6187 - val_mae: 0.6187 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "247/247 [==============================] - 203s 822ms/step - loss: 0.5918 - mae: 0.5918 - val_loss: 0.6192 - val_mae: 0.6192 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "247/247 [==============================] - 203s 823ms/step - loss: 0.5901 - mae: 0.5901 - val_loss: 0.6152 - val_mae: 0.6152 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "247/247 [==============================] - 206s 833ms/step - loss: 0.5916 - mae: 0.5916 - val_loss: 0.6172 - val_mae: 0.6172 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "247/247 [==============================] - 203s 823ms/step - loss: 0.5920 - mae: 0.5920 - val_loss: 0.6146 - val_mae: 0.6146 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "247/247 [==============================] - 193s 783ms/step - loss: 0.5901 - mae: 0.5901 - val_loss: 0.6144 - val_mae: 0.6144 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "247/247 [==============================] - 195s 792ms/step - loss: 0.5882 - mae: 0.5882 - val_loss: 0.6143 - val_mae: 0.6143 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "247/247 [==============================] - 197s 800ms/step - loss: 0.5842 - mae: 0.5842 - val_loss: 0.6112 - val_mae: 0.6112 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "247/247 [==============================] - 193s 781ms/step - loss: 0.5839 - mae: 0.5839 - val_loss: 0.6215 - val_mae: 0.6215 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "247/247 [==============================] - 201s 813ms/step - loss: 0.5845 - mae: 0.5845 - val_loss: 0.6058 - val_mae: 0.6058 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "247/247 [==============================] - 198s 801ms/step - loss: 0.5806 - mae: 0.5806 - val_loss: 0.6093 - val_mae: 0.6093 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "247/247 [==============================] - 202s 818ms/step - loss: 0.5795 - mae: 0.5795 - val_loss: 0.6055 - val_mae: 0.6055 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "247/247 [==============================] - 202s 820ms/step - loss: 0.5807 - mae: 0.5807 - val_loss: 0.6074 - val_mae: 0.6074 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "247/247 [==============================] - 198s 802ms/step - loss: 0.5771 - mae: 0.5771 - val_loss: 0.6028 - val_mae: 0.6028 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "247/247 [==============================] - 197s 797ms/step - loss: 0.5765 - mae: 0.5765 - val_loss: 0.6057 - val_mae: 0.6057 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "247/247 [==============================] - 200s 812ms/step - loss: 0.5738 - mae: 0.5738 - val_loss: 0.6003 - val_mae: 0.6003 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "247/247 [==============================] - 201s 814ms/step - loss: 0.5731 - mae: 0.5731 - val_loss: 0.6015 - val_mae: 0.6015 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "247/247 [==============================] - 199s 806ms/step - loss: 0.5712 - mae: 0.5712 - val_loss: 0.6098 - val_mae: 0.6098 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "247/247 [==============================] - 197s 799ms/step - loss: 0.5694 - mae: 0.5694 - val_loss: 0.5986 - val_mae: 0.5986 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "247/247 [==============================] - 205s 830ms/step - loss: 0.5698 - mae: 0.5698 - val_loss: 0.5997 - val_mae: 0.5997 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "247/247 [==============================] - 198s 802ms/step - loss: 0.5670 - mae: 0.5670 - val_loss: 0.5975 - val_mae: 0.5975 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "247/247 [==============================] - 205s 831ms/step - loss: 0.5669 - mae: 0.5669 - val_loss: 0.6060 - val_mae: 0.6060 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "247/247 [==============================] - 200s 812ms/step - loss: 0.5654 - mae: 0.5654 - val_loss: 0.5953 - val_mae: 0.5953 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "247/247 [==============================] - 205s 830ms/step - loss: 0.5651 - mae: 0.5651 - val_loss: 0.5932 - val_mae: 0.5932 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "247/247 [==============================] - 205s 832ms/step - loss: 0.5615 - mae: 0.5615 - val_loss: 0.5982 - val_mae: 0.5982 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "247/247 [==============================] - 208s 844ms/step - loss: 0.5605 - mae: 0.5605 - val_loss: 0.5998 - val_mae: 0.5998 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "247/247 [==============================] - 202s 818ms/step - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5880 - val_mae: 0.5880 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "247/247 [==============================] - 204s 828ms/step - loss: 0.5590 - mae: 0.5590 - val_loss: 0.5865 - val_mae: 0.5865 - lr: 5.0000e-04\n",
      "Epoch 49/60\n",
      "247/247 [==============================] - 201s 813ms/step - loss: 0.5570 - mae: 0.5570 - val_loss: 0.5961 - val_mae: 0.5961 - lr: 5.0000e-04\n",
      "Epoch 50/60\n",
      "247/247 [==============================] - 202s 818ms/step - loss: 0.5579 - mae: 0.5579 - val_loss: 0.5893 - val_mae: 0.5893 - lr: 5.0000e-04\n",
      "Epoch 51/60\n",
      "247/247 [==============================] - 202s 816ms/step - loss: 0.5565 - mae: 0.5565 - val_loss: 0.5866 - val_mae: 0.5866 - lr: 5.0000e-04\n",
      "Epoch 52/60\n",
      "247/247 [==============================] - 199s 806ms/step - loss: 0.5462 - mae: 0.5462 - val_loss: 0.5788 - val_mae: 0.5788 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "247/247 [==============================] - 203s 821ms/step - loss: 0.5427 - mae: 0.5427 - val_loss: 0.5772 - val_mae: 0.5772 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "247/247 [==============================] - 201s 816ms/step - loss: 0.5429 - mae: 0.5429 - val_loss: 0.5757 - val_mae: 0.5757 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "247/247 [==============================] - 204s 828ms/step - loss: 0.5419 - mae: 0.5419 - val_loss: 0.5791 - val_mae: 0.5791 - lr: 2.5000e-04\n",
      "Epoch 56/60\n",
      "247/247 [==============================] - 201s 816ms/step - loss: 0.5421 - mae: 0.5421 - val_loss: 0.5771 - val_mae: 0.5771 - lr: 2.5000e-04\n",
      "Epoch 57/60\n",
      "247/247 [==============================] - 201s 815ms/step - loss: 0.5413 - mae: 0.5413 - val_loss: 0.5741 - val_mae: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 58/60\n",
      "247/247 [==============================] - 203s 823ms/step - loss: 0.5393 - mae: 0.5393 - val_loss: 0.5725 - val_mae: 0.5725 - lr: 2.5000e-04\n",
      "Epoch 59/60\n",
      "247/247 [==============================] - 202s 818ms/step - loss: 0.5388 - mae: 0.5388 - val_loss: 0.5724 - val_mae: 0.5724 - lr: 2.5000e-04\n",
      "Epoch 60/60\n",
      "247/247 [==============================] - 198s 801ms/step - loss: 0.5375 - mae: 0.5375 - val_loss: 0.5750 - val_mae: 0.5750 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "history1 = model1.fit(train_x.astype(np.float32),train_y.astype(np.float32),\n",
    "                    batch_size = 128,\n",
    "                    epochs = 60,\n",
    "                    callbacks = [lr_reduce,early_stopping],\n",
    "                    validation_data = (test_x.astype(np.float32), test_y.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练时间为：12672.57秒\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"模型训练时间为：{:.2f}秒\".format(run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'lr'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f56884d1d50>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.epoch,history1.history['mae'],c='b')\n",
    "plt.plot(history1.epoch,history1.history['val_mae'],c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model1.evaluate(test_x.astype(np.float32), test_y.astype(np.float32),verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f584e6afdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f584e6afdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f584e6afdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f5738da4b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f5738da4b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f5738da4b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TCI_prediction_road54_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TCI_prediction_road54_model/assets\n"
     ]
    }
   ],
   "source": [
    "#保存模型\n",
    "model1.save('TCI_prediction_road%d_model'%number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# （六）数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>EXPONENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40609</th>\n",
       "      <td>2018/11/19 0:05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40610</th>\n",
       "      <td>2018/11/19 0:10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40611</th>\n",
       "      <td>2018/11/19 0:15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40612</th>\n",
       "      <td>2018/11/19 0:20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40613</th>\n",
       "      <td>2018/11/19 0:25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42043</th>\n",
       "      <td>2018/11/23 23:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42044</th>\n",
       "      <td>2018/11/23 23:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42045</th>\n",
       "      <td>2018/11/23 23:45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42046</th>\n",
       "      <td>2018/11/23 23:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42047</th>\n",
       "      <td>2018/11/23 23:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  Monday  Tuesday  Wednesday  Thursday  Friday  \\\n",
       "40609   2018/11/19 0:05       0        1          0         0       0   \n",
       "40610   2018/11/19 0:10       0        1          0         0       0   \n",
       "40611   2018/11/19 0:15       0        1          0         0       0   \n",
       "40612   2018/11/19 0:20       0        1          0         0       0   \n",
       "40613   2018/11/19 0:25       0        1          0         0       0   \n",
       "...                 ...     ...      ...        ...       ...     ...   \n",
       "42043  2018/11/23 23:35       0        0          0         0       0   \n",
       "42044  2018/11/23 23:40       0        0          0         0       0   \n",
       "42045  2018/11/23 23:45       0        0          0         0       0   \n",
       "42046  2018/11/23 23:50       0        0          0         0       0   \n",
       "42047  2018/11/23 23:55       0        0          0         0       0   \n",
       "\n",
       "       Saturday  Sunday  EXPONENT  \n",
       "40609         0       0         2  \n",
       "40610         0       0         1  \n",
       "40611         0       0         2  \n",
       "40612         0       0         2  \n",
       "40613         0       0         1  \n",
       "...         ...     ...       ...  \n",
       "42043         1       0         2  \n",
       "42044         1       0         2  \n",
       "42045         1       0         2  \n",
       "42046         1       0         2  \n",
       "42047         1       0         2  \n",
       "\n",
       "[1439 rows x 9 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_roadData.tail(288*5-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 2],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 2],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 2],\n",
       "       [0, 0, 0, ..., 1, 0, 2],\n",
       "       [0, 0, 0, ..., 1, 0, 2]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#因为是一个单输入和单输出，所以只需要提取出roadData中的第三列数据，然后重新赋值给roadData即可\n",
    "#因为要预测2018年11月24日的数据，因此获取后面的倒数288*5天的数据\n",
    "#此时输出的结果是一个二维array数组\n",
    "for_predict_roadData = corrected_roadData.iloc[40609:,1:].values\n",
    "for_predict_roadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 8)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_predict_roadData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#创建一个空列表for_predict_data_，每六天的数据为一组（共1152条），将全部数据（共76032条）去除用于预测的数据（2015条）进行划分（全部数据量/六天的数据总量）组，每条数据只有一个变量\n",
    "for_predict_data_= []\n",
    "for i in range(len(for_predict_roadData)-sequence_len-delay+1):\n",
    "    for_predict_data_.append(for_predict_roadData[i:i+sequence_len+delay])\n",
    "#把data_转化为array数组，三维（全部数据量，每组数据量，每条数据所含变量）\n",
    "for_predict_data_ = np.array(for_predict_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 1152, 8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_predict_data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#高维数组切片，切出x（特征）和y（标签）\n",
    "for_predict_x = for_predict_data_[: , :3*288, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_predict_y = for_predict_data_[: ,-1, 7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 0, ..., 0, 0, 2],\n",
       "        [0, 1, 0, ..., 0, 0, 1],\n",
       "        [0, 1, 0, ..., 0, 0, 2],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 3],\n",
       "        [0, 0, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 0, ..., 0, 0, 1]],\n",
       "\n",
       "       [[0, 1, 0, ..., 0, 0, 1],\n",
       "        [0, 1, 0, ..., 0, 0, 2],\n",
       "        [0, 1, 0, ..., 0, 0, 2],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1]],\n",
       "\n",
       "       [[0, 1, 0, ..., 0, 0, 2],\n",
       "        [0, 1, 0, ..., 0, 0, 2],\n",
       "        [0, 1, 0, ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 1, 0, ..., 0, 0, 1],\n",
       "        [0, 1, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 1, ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 0, ..., 0, 0, 1]],\n",
       "\n",
       "       [[0, 1, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 1, ..., 0, 0, 1],\n",
       "        [0, 0, 1, ..., 0, 0, 2],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 2]],\n",
       "\n",
       "       [[0, 0, 1, ..., 0, 0, 1],\n",
       "        [0, 0, 1, ..., 0, 0, 2],\n",
       "        [0, 0, 1, ..., 0, 0, 2],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 2],\n",
       "        [0, 0, 0, ..., 0, 0, 1]]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_predict_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_predict_x = (for_predict_x - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f56a80b9cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f56a80b9cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f56a80b9cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9/9 [==============================] - 1s 121ms/step\n"
     ]
    }
   ],
   "source": [
    "#一次性预测未来多个时刻的数据\n",
    "pre_test = model1.predict(for_predict_x.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9221141 ]\n",
      " [1.9387088 ]\n",
      " [1.9343488 ]\n",
      " [1.9401145 ]\n",
      " [1.9083364 ]\n",
      " [1.8026228 ]\n",
      " [1.6663909 ]\n",
      " [1.5083566 ]\n",
      " [1.3256385 ]\n",
      " [1.1913064 ]\n",
      " [1.086967  ]\n",
      " [1.0257354 ]\n",
      " [1.0138752 ]\n",
      " [1.0086215 ]\n",
      " [1.0114441 ]\n",
      " [1.015095  ]\n",
      " [1.0183607 ]\n",
      " [1.0209993 ]\n",
      " [1.0261707 ]\n",
      " [1.0097994 ]\n",
      " [1.0254264 ]\n",
      " [1.0241988 ]\n",
      " [1.0254836 ]\n",
      " [1.0300192 ]\n",
      " [1.0244346 ]\n",
      " [1.0121044 ]\n",
      " [1.0279132 ]\n",
      " [1.0148048 ]\n",
      " [1.0255587 ]\n",
      " [0.9979332 ]\n",
      " [1.0170767 ]\n",
      " [1.004614  ]\n",
      " [1.0083373 ]\n",
      " [1.0095274 ]\n",
      " [1.0118749 ]\n",
      " [1.0146654 ]\n",
      " [1.0172911 ]\n",
      " [1.0194237 ]\n",
      " [1.0208163 ]\n",
      " [1.0213714 ]\n",
      " [1.0217888 ]\n",
      " [1.0184412 ]\n",
      " [1.0179843 ]\n",
      " [1.0144331 ]\n",
      " [1.0062296 ]\n",
      " [0.99267197]\n",
      " [0.9850636 ]\n",
      " [0.9823799 ]\n",
      " [1.0222285 ]\n",
      " [1.0369225 ]\n",
      " [1.03375   ]\n",
      " [1.0310749 ]\n",
      " [1.0290482 ]\n",
      " [1.0275764 ]\n",
      " [1.0265753 ]\n",
      " [1.0262008 ]\n",
      " [1.0261731 ]\n",
      " [1.0263741 ]\n",
      " [1.0268724 ]\n",
      " [1.0471197 ]\n",
      " [1.1497705 ]\n",
      " [1.2842999 ]\n",
      " [1.4590375 ]\n",
      " [1.7579916 ]\n",
      " [1.8838174 ]\n",
      " [1.9562495 ]\n",
      " [1.9845057 ]\n",
      " [1.9974082 ]\n",
      " [1.9940434 ]\n",
      " [2.001395  ]\n",
      " [2.0000153 ]\n",
      " [1.9895003 ]\n",
      " [1.986243  ]\n",
      " [1.9866378 ]\n",
      " [1.9890804 ]\n",
      " [2.0350018 ]\n",
      " [1.9849689 ]\n",
      " [1.9962308 ]\n",
      " [2.0228698 ]\n",
      " [2.0271447 ]\n",
      " [2.0846143 ]\n",
      " [1.9732914 ]\n",
      " [2.0144982 ]\n",
      " [2.0178213 ]\n",
      " [2.2196586 ]\n",
      " [2.3561082 ]\n",
      " [2.7018921 ]\n",
      " [2.9383981 ]\n",
      " [2.9823208 ]\n",
      " [3.0020342 ]\n",
      " [3.0030942 ]\n",
      " [2.9963286 ]\n",
      " [3.0015402 ]\n",
      " [3.0062099 ]\n",
      " [3.005641  ]\n",
      " [3.015225  ]\n",
      " [3.013639  ]\n",
      " [3.0122478 ]\n",
      " [3.0104575 ]\n",
      " [3.0035458 ]\n",
      " [2.9997683 ]\n",
      " [3.006652  ]\n",
      " [3.009109  ]\n",
      " [3.0101743 ]\n",
      " [3.0175974 ]\n",
      " [3.017861  ]\n",
      " [3.0181117 ]\n",
      " [3.0184703 ]\n",
      " [3.009413  ]\n",
      " [3.0104258 ]\n",
      " [3.0187879 ]\n",
      " [3.0172753 ]\n",
      " [3.0185313 ]\n",
      " [3.0228999 ]\n",
      " [3.0415015 ]\n",
      " [3.1417315 ]\n",
      " [3.5074928 ]\n",
      " [3.8978686 ]\n",
      " [4.006947  ]\n",
      " [4.013638  ]\n",
      " [4.018757  ]\n",
      " [4.0172687 ]\n",
      " [4.015107  ]\n",
      " [4.008874  ]\n",
      " [4.0018663 ]\n",
      " [4.009086  ]\n",
      " [4.0018444 ]\n",
      " [4.002478  ]\n",
      " [4.0143914 ]\n",
      " [4.030529  ]\n",
      " [4.0310845 ]\n",
      " [4.034324  ]\n",
      " [4.003313  ]\n",
      " [3.9835804 ]\n",
      " [3.940044  ]\n",
      " [3.914904  ]\n",
      " [3.9138389 ]\n",
      " [3.797492  ]\n",
      " [3.4097946 ]\n",
      " [3.1437297 ]\n",
      " [3.0883608 ]\n",
      " [3.0783138 ]\n",
      " [3.0632515 ]\n",
      " [3.0427532 ]\n",
      " [3.0168595 ]\n",
      " [2.9970407 ]\n",
      " [2.9908729 ]\n",
      " [3.0023873 ]\n",
      " [3.0067034 ]\n",
      " [2.9858868 ]\n",
      " [3.0002532 ]\n",
      " [3.0066452 ]\n",
      " [3.007405  ]\n",
      " [3.0072756 ]\n",
      " [3.0065079 ]\n",
      " [3.0052996 ]\n",
      " [3.0038915 ]\n",
      " [3.0024526 ]\n",
      " [3.0350094 ]\n",
      " [3.013353  ]\n",
      " [2.9877033 ]\n",
      " [2.992552  ]\n",
      " [2.996968  ]\n",
      " [2.9959745 ]\n",
      " [3.0226076 ]\n",
      " [3.0502396 ]\n",
      " [3.026105  ]\n",
      " [3.1548371 ]\n",
      " [3.1282015 ]\n",
      " [3.0960197 ]\n",
      " [3.3131926 ]\n",
      " [3.6325915 ]\n",
      " [3.8891492 ]\n",
      " [3.9971135 ]\n",
      " [4.0276403 ]\n",
      " [4.044079  ]\n",
      " [4.0372596 ]\n",
      " [4.021752  ]\n",
      " [4.0169625 ]\n",
      " [4.0137153 ]\n",
      " [4.008953  ]\n",
      " [4.002391  ]\n",
      " [3.985453  ]\n",
      " [3.9704509 ]\n",
      " [3.9718947 ]\n",
      " [3.9794514 ]\n",
      " [3.9607959 ]\n",
      " [3.969765  ]\n",
      " [3.9581335 ]\n",
      " [3.972452  ]\n",
      " [3.9643848 ]\n",
      " [3.9822464 ]\n",
      " [3.9779708 ]\n",
      " [3.9937918 ]\n",
      " [4.0122876 ]\n",
      " [4.0058446 ]\n",
      " [4.0215287 ]\n",
      " [4.0347395 ]\n",
      " [4.02914   ]\n",
      " [4.038386  ]\n",
      " [4.0334196 ]\n",
      " [4.047065  ]\n",
      " [4.0672956 ]\n",
      " [4.089318  ]\n",
      " [4.1207705 ]\n",
      " [4.2070675 ]\n",
      " [4.3413067 ]\n",
      " [4.5086894 ]\n",
      " [4.61359   ]\n",
      " [4.786714  ]\n",
      " [4.842688  ]\n",
      " [4.929659  ]\n",
      " [4.9951386 ]\n",
      " [5.0816493 ]\n",
      " [5.082306  ]\n",
      " [5.1230164 ]\n",
      " [5.153937  ]\n",
      " [5.185049  ]\n",
      " [5.218039  ]\n",
      " [5.275128  ]\n",
      " [5.262876  ]\n",
      " [5.275111  ]\n",
      " [5.279945  ]\n",
      " [5.2907157 ]\n",
      " [5.2752404 ]\n",
      " [5.131518  ]\n",
      " [4.806832  ]\n",
      " [4.5853305 ]\n",
      " [4.293623  ]\n",
      " [4.156849  ]\n",
      " [4.1038465 ]\n",
      " [4.071087  ]\n",
      " [4.028211  ]\n",
      " [4.000263  ]\n",
      " [3.969381  ]\n",
      " [3.9018152 ]\n",
      " [3.9088535 ]\n",
      " [3.9189415 ]\n",
      " [4.13901   ]\n",
      " [4.009816  ]\n",
      " [4.1972656 ]\n",
      " [4.1953397 ]\n",
      " [4.143253  ]\n",
      " [4.1162076 ]\n",
      " [4.009093  ]\n",
      " [3.958578  ]\n",
      " [3.8287504 ]\n",
      " [3.7204218 ]\n",
      " [3.5231483 ]\n",
      " [3.0779219 ]\n",
      " [2.995661  ]\n",
      " [3.0117583 ]\n",
      " [3.00109   ]\n",
      " [2.987394  ]\n",
      " [2.9993873 ]\n",
      " [2.9958107 ]\n",
      " [2.979533  ]\n",
      " [2.8235335 ]\n",
      " [2.4332397 ]\n",
      " [2.0827901 ]\n",
      " [2.0179281 ]\n",
      " [1.9757233 ]\n",
      " [1.9947228 ]\n",
      " [2.007867  ]\n",
      " [2.0447736 ]\n",
      " [2.0462704 ]\n",
      " [2.054753  ]\n",
      " [2.0492735 ]\n",
      " [2.0429678 ]\n",
      " [2.014027  ]\n",
      " [2.0035632 ]\n",
      " [2.0040932 ]\n",
      " [2.0031066 ]\n",
      " [2.0156722 ]\n",
      " [1.989336  ]\n",
      " [1.9731224 ]\n",
      " [1.9724255 ]\n",
      " [1.9746962 ]\n",
      " [1.9752674 ]\n",
      " [1.9848795 ]\n",
      " [1.9769983 ]\n",
      " [1.9767668 ]\n",
      " [1.9619229 ]\n",
      " [1.972821  ]\n",
      " [1.9653282 ]\n",
      " [1.996525  ]\n",
      " [2.0035224 ]\n",
      " [2.0228357 ]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test = np.round(pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把二维转化为一维\n",
    "pre_test = [i for arr in pre_test for i in arr ]\n",
    "pre_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print(pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_real_y = (corrected_roadData.tail(288)).EXPONENT.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 3, 1, 2, 2, 2, 2,\n",
       "       1, 3, 1, 1, 2, 3, 3, 4, 3, 1, 3, 1, 3, 3, 1, 2, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 2, 2, 2, 3, 2, 2, 2, 1, 1, 2, 3, 3, 2, 1, 2, 2, 1, 2, 3,\n",
       "       3, 3, 4, 3, 4, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       3, 4, 4, 4, 3, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 2, 3, 3, 2, 3, 2,\n",
       "       3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 3, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 4, 5, 4, 3, 4, 3, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 5,\n",
       "       5, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
       "       3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 3, 2, 3, 2,\n",
       "       2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 178\n",
      "预测的正确率为：0.6180555555555556\n"
     ]
    }
   ],
   "source": [
    "sum1=0\n",
    "sum2=0\n",
    "for i in range(0,288):\n",
    "    if future_real_y[i] == for_predict_y[i]:\n",
    "        sum1+=1\n",
    "    if future_real_y[i] == pre_test[i]:\n",
    "        sum2+=1    \n",
    "print(sum1,sum2)\n",
    "print('预测的正确率为：' + str(sum2/sum1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# （七）把预测的数据写入Excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook\n",
    "#将数据写入到Excel并保存\n",
    "wb = Workbook()\n",
    "sheet1 = wb.active\n",
    "sheet1.title = 'road%d'%number\n",
    "col_name = ['TCI_prediction_of_road%d'%number]   #注意修改此处\n",
    "variable_name = [pre_test]\n",
    "for j in range(1,len(col_name)+1):\n",
    "    sheet1.cell(1,j,col_name[j-1])\n",
    "    for i in range(2,len(variable_name[j-1])+2):\n",
    "        sheet1.cell(i,j,variable_name[j-1][i-2])\n",
    "wb.save('TCI_prediction_of_road%d.xlsx'%number)\n",
    "print('已保存')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 八、加载已有模型进行预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TCI_prediction_road%d_model\"%number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
