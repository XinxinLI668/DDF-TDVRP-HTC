{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、导入工具包 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据处理库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3' # 只显示 Error\n",
    "#数据保存为Excel\n",
    "import openpyxl\n",
    "#随机生成数据\n",
    "import random\n",
    "#使得输出的数据可以完整打印出来全部的行列\n",
    "#显示所有列\n",
    "#pd.set_option('display.max_columns',None)\n",
    "#显示所有行\n",
    "#pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、读入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这次数据比较多，数据总量超过Excel单个单元表的最大容量，所以在API接口获取时，分为了6个Excel储存，日后可以学习下数据库用于储存大规模数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取全部路径2018年3月1日到4月22日的数据\n",
    "data1 = pd.read_excel(r'ShenZhen-roadData(180301-181124)\\180301-180422.xlsx',engine='openpyxl')\n",
    "#读取全部路径2018年4月23日到6月10日的数据\n",
    "data2 = pd.read_excel(r'ShenZhen-roadData(180301-181124)\\180423-180610.xlsx',engine='openpyxl')\n",
    "#读取全部路径2018年6月11日到7月16日的数据\n",
    "data3 = pd.read_excel(r'ShenZhen-roadData(180301-181124)\\180611-180716.xlsx',engine='openpyxl')\n",
    "#读取全部路径2018年7月17日到9月1日的数据\n",
    "data4 = pd.read_excel(r'ShenZhen-roadData(180301-181124)\\180717-180901.xlsx',engine='openpyxl')\n",
    "#读取全部路径2018年9月2日到10月21日的数据\n",
    "data5 = pd.read_excel(r'ShenZhen-roadData(180301-181124)\\180902-181021.xlsx',engine='openpyxl')\n",
    "#读取全部路径2018年10月22日到11月24日的数据\n",
    "data6 = pd.read_excel(r'ShenZhen-roadData(180301-181124)\\181022-181124.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、定义提取单一路径数据的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将每个数据集下面的单条路径的数据提取出来，并把单个路径的全部数据合并到一起 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （一）编写函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_road(num): #确定自己是处理哪一条数据的,num是一个数字，指的是某一条路径的编号\n",
    "    #<------从每个数据集都仅提取出一条路径的全部数据---------->\n",
    "    #提取单一路径（路径2为例）2018年3月1日到4月22日的数据\n",
    "    roadData1 = data1.loc[data1['BLOCKID']==num]\n",
    "    #提取单一路径（路径2为例）2018年4月23日到6月10日的数据\n",
    "    roadData2 = data2.loc[data2['BLOCKID']==num]\n",
    "    #提取单一路径（路径2为例）2018年6月11日到7月16日的数据\n",
    "    roadData3 = data3.loc[data3['BLOCKID']==num]\n",
    "    #提取单一路径（路径2为例）2018年7月17日到9月1日的数据\n",
    "    roadData4 = data4.loc[data4['BLOCKID']==num]\n",
    "    #提取单一路径（路径2为例）2018年9月2日到10月21日的数据\n",
    "    roadData5 = data5.loc[data5['BLOCKID']==num]\n",
    "    #提取单一路径（路径2为例）2018年10月23日到11月24日的数据\n",
    "    roadData6 = data6.loc[data6['BLOCKID']==num]\n",
    "    #<------将每个数据集的一条路径的全部数据合并为一个dataframe---------->\n",
    "    #把上述6个数据集的数据合并为一个dataframe\n",
    "    '''\n",
    "    #原来版本语法\n",
    "    roadData = roadData1.append(roadData2)   #把roadData2的数据添加到roadData1后面，并形成一个新的dataframe，命名为roadData\n",
    "    roadData = roadData.append(roadData3)    #把roadData3的数据添加到roadData后面\n",
    "    roadData = roadData.append(roadData4)    #把roadData4的数据添加到roadData后面\n",
    "    roadData = roadData.append(roadData5)    #把roadData5的数据添加到roadData后面\n",
    "    roadData = roadData.append(roadData6)    #把roadData6的数据添加到roadData后面'''\n",
    "    #新版本语法\n",
    "    roadData = pd.concat([roadData1, roadData2,roadData3,roadData4,roadData5,roadData6], ignore_index=True)\n",
    "    return roadData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （二）函数测试 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME1</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>EXPONENT</th>\n",
       "      <th>BLOCKID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721036</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721165</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721229</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721319</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721325</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TIME1  PERIOD  EXPONENT  BLOCKID\n",
       "67      2018-03-01 00:00:00       1         1        1\n",
       "84      2018-03-01 00:00:00       2         1        1\n",
       "192     2018-03-01 00:00:00       3         1        1\n",
       "261     2018-03-01 00:00:00       4         1        1\n",
       "345     2018-03-01 00:00:00       5         1        1\n",
       "...                     ...     ...       ...      ...\n",
       "721036  2018-11-24 00:00:00     283         1        1\n",
       "721165  2018-11-24 00:00:00     284         1        1\n",
       "721229  2018-11-24 00:00:00     285         1        1\n",
       "721319  2018-11-24 00:00:00     286         1        1\n",
       "721325  2018-11-24 00:00:00     287         1        1\n",
       "\n",
       "[74988 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 1\n",
    "roadData = extract_single_road(num) \n",
    "roadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74988 entries, 67 to 721325\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   TIME1     74988 non-null  object\n",
      " 1   PERIOD    74988 non-null  int64 \n",
      " 2   EXPONENT  74988 non-null  int64 \n",
      " 3   BLOCKID   74988 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#查看roadData数据的情况\n",
    "roadData.info(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME1</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>EXPONENT</th>\n",
       "      <th>BLOCKID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TIME1  PERIOD  EXPONENT  BLOCKID\n",
       "67   2018-03-01 00:00:00       1         1        1\n",
       "84   2018-03-01 00:00:00       2         1        1\n",
       "192  2018-03-01 00:00:00       3         1        1\n",
       "261  2018-03-01 00:00:00       4         1        1\n",
       "345  2018-03-01 00:00:00       5         1        1\n",
       "438  2018-03-01 00:00:00       6         1        1\n",
       "501  2018-03-01 00:00:00       7         1        1\n",
       "551  2018-03-01 00:00:00       8         1        1\n",
       "658  2018-03-01 00:00:00       9         1        1\n",
       "696  2018-03-01 00:00:00      10         1        1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看roadData数据的情况\n",
    "roadData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-07-16 00:00:00    419\n",
       "2018-10-23 00:00:00    290\n",
       "2018-07-23 00:00:00    289\n",
       "2018-09-12 00:00:00    289\n",
       "2018-09-21 00:00:00    289\n",
       "                      ... \n",
       "2018-04-16 00:00:00    168\n",
       "2018-07-17 00:00:00    127\n",
       "2018-07-14 00:00:00    118\n",
       "2018-05-05 00:00:00    109\n",
       "2018-07-15 00:00:00     15\n",
       "Name: TIME1, Length: 268, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看每一天是否有重复观测值和缺失观测值，返回的数据类型是pd.series类型\n",
    "roadData.TIME1.value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 发现部分日期的数据有缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、定义增加缺失值和剔除重复值的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （一）寻找较优补值策略：补值方法准确率对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.前项补值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_supplement_accuracy_rate(roadData,sample_num):\n",
    "    #统计TIME1列数据的频数（合理的频数为288），确认数据重复和缺失情况\n",
    "    a = roadData.TIME1.value_counts()  #此时a是series类型，根据a的结果，可以发现有重复数据和缺失数据\n",
    "    #针对有重复数据的，删除重复数据（直接在原dataframe上进行操作）\n",
    "    roadData.drop_duplicates(inplace=True)\n",
    "    #将数据按照时间顺序（先对TIME1再对PERIOD），（从小到大排序），（直接在原dataframe上进行操作）\n",
    "    roadData.sort_values(by = ['TIME1','PERIOD'],ascending=True,inplace=True)\n",
    "    #重置索引，让索引按照一个顺序下来\n",
    "    roadData=roadData.reset_index()\n",
    "    #删除退居二线的原来的没用的索引\n",
    "    del roadData['index']\n",
    "    #返回全部无缺失观测值的天数索引值，返回值是一个列表\n",
    "    b = list(a[a.values==288].index)\n",
    "    #对b的天数增序排列\n",
    "    b.sort()\n",
    "    \n",
    "    #遍历所有的无确实观测值的天数的索引值，提取出某一天的全部数据（dataframe），然后依次添加每一天的数据（dataframe）进去，合并为一个大（dataframe）\n",
    "    roadData_no_queshi = roadData[(roadData.TIME1 == b[0])]\n",
    "    for i in range(1,len(b)):\n",
    "        new_roadData_no_queshi = roadData[(roadData.TIME1 == b[i])]  #类型为（dataframe）\n",
    "        roadData_no_queshi = roadData_no_queshi.append(new_roadData_no_queshi)    #roadData_no_queshi是提取出来的全部不含缺失值的数据，类型为（dataframe）\n",
    "    \n",
    "    #随机从某条路径的数据中抽取 n 条数据，为无放回抽样\n",
    "    sample = roadData_no_queshi.sample(n=sample_num,replace=False)\n",
    "    sample\n",
    "    \n",
    "    #遍历所抽取的 n 条数据，使用补值方法进行补值，查看正确率\n",
    "    #创建一个空列表用于储存补的值\n",
    "    supplemental_EXPONENT_list = []\n",
    "    sample_TIME1 = list(sample['TIME1'].values)\n",
    "    sample_PERIOD = list(sample['PERIOD'].values)\n",
    "    for i in range(sample.shape[0]):\n",
    "        indexOfTrueValue = roadData[(roadData.TIME1 == sample_TIME1[i]) & (roadData.PERIOD == sample_PERIOD[i])].index\n",
    "        supplemental_EXPONENT = roadData.EXPONENT.values[indexOfTrueValue-1]\n",
    "        supplemental_EXPONENT_list = supplemental_EXPONENT_list + [supplemental_EXPONENT]\n",
    "    \n",
    "    #比较所有样本的拥堵状况的真实值和增补的值的差异，计算补值方法的正确度\n",
    "    sample_EXPONENT = list(sample['EXPONENT'].values)\n",
    "    sum = 0\n",
    "    for i in range(len(sample_EXPONENT)):\n",
    "        if sample_EXPONENT[i]==supplemental_EXPONENT_list[i]:\n",
    "            sum += 1\n",
    "    accuracy_rate = sum/len(sample_EXPONENT)\n",
    "    print(accuracy_rate)   \n",
    "    \n",
    "    return accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = forward_supplement_accuracy_rate(roadData,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.后项补值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_supplement_accuracy_rate(roadData,sample_num):\n",
    "    #统计TIME1列数据的频数（合理的频数为288），确认数据重复和缺失情况\n",
    "    a = roadData.TIME1.value_counts()  #此时a是series类型，根据a的结果，可以发现有重复数据和缺失数据\n",
    "    #针对有重复数据的，删除重复数据（直接在原dataframe上进行操作）\n",
    "    roadData.drop_duplicates(inplace=True)\n",
    "    #将数据按照时间顺序（先对TIME1再对PERIOD），（从小到大排序），（直接在原dataframe上进行操作）\n",
    "    roadData.sort_values(by = ['TIME1','PERIOD'],ascending=True,inplace=True)\n",
    "    #重置索引，让索引按照一个顺序下来\n",
    "    roadData=roadData.reset_index()\n",
    "    #删除退居二线的原来的没用的索引\n",
    "    del roadData['index']\n",
    "    #返回全部无缺失观测值的天数索引值，返回值是一个列表\n",
    "    b = list(a[a.values==288].index)\n",
    "    #对b的天数增序排列\n",
    "    b.sort()\n",
    "    \n",
    "    #遍历所有的无确实观测值的天数的索引值，提取出某一天的全部数据（dataframe），然后依次添加每一天的数据（dataframe）进去，合并为一个大（dataframe）\n",
    "    roadData_no_queshi = roadData[(roadData.TIME1 == b[0])]\n",
    "    for i in range(1,len(b)):\n",
    "        new_roadData_no_queshi = roadData[(roadData.TIME1 == b[i])]  #类型为（dataframe）\n",
    "        roadData_no_queshi = roadData_no_queshi.append(new_roadData_no_queshi)    #roadData_no_queshi是提取出来的全部不含缺失值的数据，类型为（dataframe）\n",
    "    \n",
    "    #随机从某条路径的数据中抽取 n 条数据，为无放回抽样\n",
    "    sample = roadData_no_queshi.sample(n=sample_num,replace=False)\n",
    "    sample\n",
    "    \n",
    "    #遍历所抽取的 n 条数据，使用补值方法进行补值，查看正确率\n",
    "    #创建一个空列表用于储存补的值\n",
    "    supplemental_EXPONENT_list = []\n",
    "    sample_TIME1 = list(sample['TIME1'].values)\n",
    "    sample_PERIOD = list(sample['PERIOD'].values)\n",
    "    for i in range(sample.shape[0]):\n",
    "        indexOfTrueValue = roadData[(roadData.TIME1 == sample_TIME1[i]) & (roadData.PERIOD == sample_PERIOD[i])].index\n",
    "        supplemental_EXPONENT = roadData.EXPONENT.values[indexOfTrueValue+1]\n",
    "        supplemental_EXPONENT_list = supplemental_EXPONENT_list + [supplemental_EXPONENT]\n",
    "    \n",
    "    #比较所有样本的拥堵状况的真实值和增补的值的差异，计算补值方法的正确度\n",
    "    sample_EXPONENT = list(sample['EXPONENT'].values)\n",
    "    sum = 0\n",
    "    for i in range(len(sample_EXPONENT)):\n",
    "        if sample_EXPONENT[i]==supplemental_EXPONENT_list[i]:\n",
    "            sum += 1\n",
    "    accuracy_rate = sum/len(sample_EXPONENT)\n",
    "    print(accuracy_rate)   \n",
    "    \n",
    "    return accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = backward_supplement_accuracy_rate(roadData,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.（前一刻的、前一天此刻的和上一周此刻的）加权平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_supplement_accuracy_rate(roadData,sample_num):\n",
    "    #统计TIME1列数据的频数（合理的频数为288），确认数据重复和缺失情况\n",
    "    a = roadData.TIME1.value_counts()  #此时a是series类型，根据a的结果，可以发现有重复数据和缺失数据\n",
    "    #针对有重复数据的，删除重复数据（直接在原dataframe上进行操作）\n",
    "    roadData.drop_duplicates(inplace=True)\n",
    "    #将数据按照时间顺序（先对TIME1再对PERIOD），（从小到大排序），（直接在原dataframe上进行操作）\n",
    "    roadData.sort_values(by = ['TIME1','PERIOD'],ascending=True,inplace=True)\n",
    "    #重置索引，让索引按照一个顺序下来\n",
    "    roadData=roadData.reset_index()\n",
    "    #删除退居二线的原来的没用的索引\n",
    "    del roadData['index']\n",
    "    #返回全部无缺失观测值的天数索引值，返回值是一个列表\n",
    "    b = list(a[a.values==288].index)\n",
    "    #对b的天数增序排列\n",
    "    b.sort()\n",
    "    \n",
    "    #遍历所有的无确实观测值的天数的索引值，提取出某一天的全部数据（dataframe），然后依次添加每一天的数据（dataframe）进去，合并为一个大（dataframe）\n",
    "    roadData_no_queshi = roadData[(roadData.TIME1 == b[0])]\n",
    "    for i in range(1,len(b)):\n",
    "        new_roadData_no_queshi = roadData[(roadData.TIME1 == b[i])]  #类型为（dataframe）\n",
    "        roadData_no_queshi = roadData_no_queshi.append(new_roadData_no_queshi)    #roadData_no_queshi是提取出来的全部不含缺失值的数据，类型为（dataframe）\n",
    "    \n",
    "    #随机从某条路径的数据中抽取 n 条数据，为无放回抽样\n",
    "    sample = roadData_no_queshi.sample(n=sample_num,replace=False)\n",
    "    sample\n",
    "    \n",
    "    #遍历所抽取的 n 条数据，使用补值方法进行补值，查看正确率\n",
    "    #创建一个空列表用于储存补的值\n",
    "    supplemental_EXPONENT_list = []\n",
    "    sample_TIME1 = list(sample['TIME1'].values)\n",
    "    sample_PERIOD = list(sample['PERIOD'].values)\n",
    "    for i in range(sample.shape[0]):\n",
    "        indexOfTrueValue = roadData[(roadData.TIME1 == sample_TIME1[i]) & (roadData.PERIOD == sample_PERIOD[i])].index\n",
    "        supplemental_EXPONENT = int(0.5*roadData.EXPONENT.values[indexOfTrueValue-1]+0.3*roadData.EXPONENT.values[indexOfTrueValue-288]+0.2*roadData.EXPONENT.values[indexOfTrueValue-2016])\n",
    "        supplemental_EXPONENT_list = supplemental_EXPONENT_list + [supplemental_EXPONENT]\n",
    "    \n",
    "    #比较所有样本的拥堵状况的真实值和增补的值的差异，计算补值方法的正确度\n",
    "    sample_EXPONENT = list(sample['EXPONENT'].values)\n",
    "    sum = 0\n",
    "    for i in range(len(sample_EXPONENT)):\n",
    "        if sample_EXPONENT[i]==supplemental_EXPONENT_list[i]:\n",
    "            sum += 1\n",
    "    accuracy_rate = sum/len(sample_EXPONENT)\n",
    "    print(accuracy_rate)   \n",
    "    \n",
    "    return accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = our_supplement_accuracy_rate(roadData,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 经过测试，最终选择加权补值法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （二）编写函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Handle_duplicate_and_missing_values(roadData,num): #num为道路序号\n",
    "    #统计TIME1列数据的频数（合理的频数为288），确认数据重复和缺失情况\n",
    "    a = roadData.TIME1.value_counts()  #此时a是series类型，根据a的结果，可以发现有重复数据和缺失数据\n",
    "    #针对有重复数据的，删除重复数据（直接在原dataframe上进行操作）\n",
    "    roadData.drop_duplicates(inplace=True)\n",
    "    #将数据按照时间顺序（先对TIME1再对PERIOD），（从小到大排序），（直接在原dataframe上进行操作）\n",
    "    roadData.sort_values(by = ['TIME1','PERIOD'],ascending=True,inplace=True)\n",
    "    #重置索引，让索引按照一个顺序下来\n",
    "    roadData=roadData.reset_index()\n",
    "    #删除退居二线的原来的没用的索引\n",
    "    del roadData['index']\n",
    "    #返回全部有缺失观测值的天数日期\n",
    "    b=list(a[a.values!=288].index)\n",
    "    #按照时间递增的顺序排序\n",
    "    b.sort()\n",
    "    for i in b:   #遍历每一个有缺失观测值的日期\n",
    "        period_list = [i for i in range(1,289)]  #建立一个观测时间段的全集\n",
    "        c = roadData.loc[roadData['TIME1']== i ]  #在roadData中提取出该日期的全部数据\n",
    "        for j in range(c.shape[0]):  #遍历每一个时间段\n",
    "            try:\n",
    "                period_list.remove(c.iloc[j,1])   #在观测时间段的全集里移走不缺失观测值的时间段\n",
    "            except:\n",
    "                continue\n",
    "        #print(period_list)\n",
    "        for j in period_list:  #现在的list是该日期下缺失观测值的时间段\n",
    "            roadData.loc [i+str(j)] = [i, j, 'none',num ]  #\n",
    "        #将数据按照时间顺序（先对TIME1再对PERIOD），（从小到大排序），（直接在原dataframe上进行操作）\n",
    "        roadData.sort_values(by = ['TIME1','PERIOD'],ascending=True,inplace=True)\n",
    "        #重置索引，让索引按照一个顺序下来\n",
    "        roadData=roadData.reset_index()\n",
    "        #删除退居二线的原来的没用的索引\n",
    "        del roadData['index']\n",
    "        #更新c\n",
    "        c = roadData.loc[roadData['TIME1']== i ]  #在roadData中提取出该日期的全部数据,含有None值了\n",
    "        for j in range(len(period_list)):  #遍历每一个时间段\n",
    "            #print('<----'+str(j)+'---->')\n",
    "            index = roadData[(roadData.TIME1==i) & (roadData.PERIOD==period_list[j])].index  #返回确定缺失日期和缺失天数在roadData中对应的索引\n",
    "            supplemental_EXPONENT = int(0.5*roadData.EXPONENT.values[index[0]-1]+0.3*roadData.EXPONENT.values[index[0]-288]+0.2*roadData.EXPONENT.values[index[0]-2016]) #采用前项补值法\n",
    "            roadData.loc[index[0],'EXPONENT'] = supplemental_EXPONENT \n",
    "            \n",
    "    return roadData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （三）测试函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME1</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>EXPONENT</th>\n",
       "      <th>BLOCKID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77179</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77180</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77181</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77182</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77183</th>\n",
       "      <td>2018-11-24 00:00:00</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77184 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TIME1  PERIOD EXPONENT  BLOCKID\n",
       "0      2018-03-01 00:00:00       1        1        1\n",
       "1      2018-03-01 00:00:00       2        1        1\n",
       "2      2018-03-01 00:00:00       3        1        1\n",
       "3      2018-03-01 00:00:00       4        1        1\n",
       "4      2018-03-01 00:00:00       5        1        1\n",
       "...                    ...     ...      ...      ...\n",
       "77179  2018-11-24 00:00:00     284        1        1\n",
       "77180  2018-11-24 00:00:00     285        1        1\n",
       "77181  2018-11-24 00:00:00     286        1        1\n",
       "77182  2018-11-24 00:00:00     287        1        1\n",
       "77183  2018-11-24 00:00:00     288        1        2\n",
       "\n",
       "[77184 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#得到处理好的roadData数据，无缺失值和重复值\n",
    "roadData = Handle_duplicate_and_missing_values(roadData,2)\n",
    "roadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadData.to_excel(r'road2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、依次提取单一路径路况信息、删重补缺、增加星期信息、将星期独热编码并保存为Excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1条路的数据已经保存.xlsx\n",
      "第2条路的数据已经保存.xlsx\n",
      "第3条路的数据已经保存.xlsx\n",
      "第4条路的数据已经保存.xlsx\n",
      "第5条路的数据已经保存.xlsx\n",
      "第6条路的数据已经保存.xlsx\n",
      "第7条路的数据已经保存.xlsx\n",
      "第8条路的数据已经保存.xlsx\n",
      "第9条路的数据已经保存.xlsx\n",
      "第10条路的数据已经保存.xlsx\n",
      "第11条路的数据已经保存.xlsx\n",
      "第12条路的数据已经保存.xlsx\n",
      "第13条路的数据已经保存.xlsx\n",
      "第14条路的数据已经保存.xlsx\n",
      "第15条路的数据已经保存.xlsx\n",
      "第16条路的数据已经保存.xlsx\n",
      "第17条路的数据已经保存.xlsx\n",
      "第18条路的数据已经保存.xlsx\n",
      "第19条路的数据已经保存.xlsx\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,73):\n",
    "    #提取单一路径数据\n",
    "    roadData = extract_single_road(num) \n",
    "    #查重补缺\n",
    "    corrected_roadData = Handle_duplicate_and_missing_values(roadData,num)\n",
    "    #增加星期信息\n",
    "    corrected_roadData['TIME1'] = pd.to_datetime(corrected_roadData['TIME1'])\n",
    "    corrected_roadData['WEEK'] = corrected_roadData['TIME1'].dt.dayofweek+1\n",
    "    #对week进行独热编码\n",
    "    corrected_roadData['Monday'] = (corrected_roadData.WEEK == 1).astype('int')\n",
    "    corrected_roadData['Tuesday'] = (corrected_roadData.WEEK == 2).astype('int')\n",
    "    corrected_roadData['Wednesday'] = (corrected_roadData.WEEK == 3).astype('int')\n",
    "    corrected_roadData['Thursday'] = (corrected_roadData.WEEK == 4).astype('int')\n",
    "    corrected_roadData['Friday'] = (corrected_roadData.WEEK == 5).astype('int')\n",
    "    corrected_roadData['Saturday'] = (corrected_roadData.WEEK == 6).astype('int')\n",
    "    corrected_roadData['Sunday'] = (corrected_roadData.WEEK == 7).astype('int')\n",
    "    #删除无用列\n",
    "    corrected_roadData.drop ('WEEK', axis=1,inplace=True)\n",
    "    corrected_roadData.drop ('BLOCKID', axis=1,inplace=True)\n",
    "    #保存\n",
    "    corrected_roadData.to_excel('road%s.xlsx'%num,engine='openpyxl')\n",
    "    print('第%s条路的数据已经保存.xlsx'%num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录：“干中学”收获的一些知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注：Excel最多支持写入1048576行数据\n",
    "- pandas最多支持读入65536行数据\n",
    "- Pandas 读取 Excel 文件的引擎是 xlrd ， xlrd 虽然同时支持 .xlsx 和 .xls 两种文件格式，但是在源码文件 xlrd/sheet.py 中限制了读取的 Excel 文件行数必须小于 65536，列数必须小于 256。\n",
    "- 这就导致，即使是 .xlsx 格式的文件， xlrd 依然不支持读取 65536 行以上的 Excel 文件（源码中还有一个行数限制是 16384，这是因为 Excel 95 时代， xls 文件所支持的最大行数是 16384）。\n",
    "\n",
    "- 解决办法\n",
    "\n",
    "- openpyxl 是一个专门用来操作 .xlsx 格式文件的 Python 库，和 xlrd 相比它对于最大行列数的支持和 .xlsx 文件所定义的最大行列数一致。\n",
    "\n",
    "- 首先安装 openpyxl ：\n",
    "\n",
    "- Pandas 的 read_excel 方法中，有 engine 字段，可以指定所使用的处理 Excel 文件的引擎，填入 openpyxl ，再读取文件就可以了。\n",
    "\n",
    "- import pandas as pd\n",
    "- df = pd.read_excel('./data.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
